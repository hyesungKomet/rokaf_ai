{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Elice 3-4 YOLO.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOT7kFYYli1IS29k7quCgsb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyesungKomet/rokaf_ai/blob/main/Elice_3_4_YOLO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YOLO(You Only Look Once)\n",
        "\n",
        "* 2-stage detector:  \n",
        "region proposal(객체로 의심되는 후보영역 찾기)을 한 뒤에 classification(후보별로 이미지 분류)이 이루어짐  \n",
        " -> Accuracy는 높지만 FPS(속도)가 느림\n",
        "ex) Faster R-CNN이 5 FPS인데 Real-time detection을 위해선 적어도 30 FPS가 필요하다고 함\n",
        "\n",
        "* 1-stage detector:  \n",
        "region proposal과 classification을 한번에 수행\n",
        "기존의 region proposal 방식이 아닌 grid 도입으로 속도 향상\n",
        "\n",
        "\n",
        "![](https://www.haxed.dk/tablesoccer/public/img/yolo-architecture.png)\n",
        "\n",
        "* 7 x 7 x 30 \n",
        "bounding box 2개의 좌표와 confidence값, 각 class의 확률 값\n",
        "![](https://user-images.githubusercontent.com/15168540/48966993-9a679e80-f01d-11e8-8f78-66a7135859eb.png)\n",
        "\n",
        "  * x: 각 grid cell의 TopLeft부터의 x좌표\n",
        "  * y: 각 grid cell의 TopLeft부터의 y좌표\n",
        "  * w: 전체 image의 width와 박스의 width의 비율\n",
        "  * h: 전체 image의 height와 박스의 height의 비율  \n",
        "  x,y가 bounding box의 가운데 좌표를 의미, w,h가 bounding box의 가로, 세로 길이를 의미\n",
        "  * C: Confidence, objectness - 해당 grid cell에 객체 존재할 지의 확률 값\n",
        "  * Class Probabilities: 해당 grid cell에서 각 class(자전거, 버스, 사람 등)일 확률 값\n",
        "\n",
        "Bounding Box에 해당하는 값 5개가 Anchor Box가 된다\n",
        "\n"
      ],
      "metadata": {
        "id": "7e5DDrZd29nd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss\n",
        "정답 box는 7 x 7 x 25\n",
        "정답인 box가 하나이므로!  \n",
        "\n",
        "* box objectness + box location + class confidence\n",
        "\n",
        "## Grid\n",
        "\n",
        "![](https://mblogthumb-phinf.pstatic.net/MjAxNzA0MjhfMjUw/MDAxNDkzMzY0NDQyNDQ5.TF2xVDnVt0LLsAqLFRmBLAxsPa1W396-hPRwiHksaoUg.TF8F434-MLBQjVvU02dXT1fduB23VquAny80Kiex4KEg.PNG.sogangori/interpret0.PNG?type=w2)\n",
        "\n",
        "두 anchor box의 PC(predicted confidence)를 각 class probabilites에 곱해서 20x1 행렬 두 개를 만든다  \n",
        "objectness와 class confidence 모두 높아야 성능이 좋기 때문!!  \n",
        "  \n",
        "1. grid가  7 x 7 이니 총 7 x 7 x 2 = 98 개의 20 x 1 행렬이 나온다\n",
        "\n",
        "  너무 많음!!\n",
        "\n",
        "  점수에 따른 바운딩 박스 필터링 후 NMS 적용!\n",
        "\n",
        "2. 20개의 class 모두에서 Class Confidence가 threshold보다 낮으면 0으로 변경\n",
        "3. Class Confidence를 내림차순으로 정렬(Class별로)\n",
        "4. 맨 앞에 가장 Confidence 높은 box가 온다\n",
        "5. 첫 Class Confidence와 다른 박스들의 IoU를 구해서 IoU threshold(보통 0.5)이상이면 0으로 바꿔준다 - Class별로니까 20번 수행하겠지?\n",
        "\n",
        "6. 이렇게 하면 98개 중 몇 개만 남을텐데, 각 박스들에서 가장 큰 Class Confidence에 해당하는 값을 지정하고 그 값(Score)이 0보다 크면 해당 Bounding Box는 그 Class를 인식하는 박스로 그리게 된다\n",
        "\n",
        "![](https://i.ibb.co/JKgny4t/image.png)"
      ],
      "metadata": {
        "id": "hg7U51XU4cU0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Yolo Layer 만들기"
      ],
      "metadata": {
        "id": "FUmdJyEbBOrT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCpxHjhfditc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import datasets, layers, models, activations, losses, optimizers, metrics\n",
        "from keras.layers import LeakyReLU\n",
        "\n",
        "def create_yolo():\n",
        "    model = models.Sequential()\n",
        "    \n",
        "    # Block1\n",
        "    model.add(layers.Convolution2D(64, (7, 7), strides=(2, 2), input_shape=(448, 448, 3), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.1))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "    # Block2\n",
        "    model.add(layers.Convolution2D(192, (3, 3), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.1))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))    \n",
        "    \n",
        "    # Block3\n",
        "    model.add(layers.Convolution2D(128, (1, 1), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.1))\n",
        "    model.add(layers.Convolution2D(256, (3, 3), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.1))\n",
        "    model.add(layers.Convolution2D(256, (1, 1), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.1))\n",
        "    model.add(layers.Convolution2D(512, (3, 3), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.1))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))    \n",
        "    \n",
        "    # Block4\n",
        "    model.add(layers.Convolution2D(256, (1, 1), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.1))\n",
        "    model.add(layers.Convolution2D(512, (3, 3), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.1))\n",
        "    model.add(layers.Convolution2D(256, (1, 1), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.1))\n",
        "    model.add(layers.Convolution2D(512, (3, 3), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.1))\n",
        "    model.add(layers.Convolution2D(256, (1, 1), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.1))\n",
        "    model.add(layers.Convolution2D(512, (3, 3), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.1))\n",
        "    model.add(layers.Convolution2D(256, (1, 1), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.1))\n",
        "    model.add(layers.Convolution2D(512, (3, 3), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.1))\n",
        "    model.add(layers.Convolution2D(512, (1, 1), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.1))\n",
        "    model.add(layers.Convolution2D(1024, (3, 3), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.1))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "    # Block5\n",
        "    model.add(layers.Convolution2D(512, (1,1), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.1))\n",
        "    model.add(layers.Convolution2D(1024, (3,3), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.1))\n",
        "    model.add(layers.Convolution2D(512,(1,1), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.1))\n",
        "    model.add(layers.Convolution2D(1024, (3,3), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.1))\n",
        "    model.add(layers.Convolution2D(1024,(3,3), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.1))\n",
        "    model.add(layers.Convolution2D(1024,(3,3), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.1))\n",
        "\n",
        "    # Block6\n",
        "    model.add(layers.Convolution2D(1024,(3,3), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.1))\n",
        "    model.add(layers.Convolution2D(1024, (3,3), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.1))\n",
        "\n",
        "    # Last Block\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(4096))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(7 * 7 * 30))\n",
        "    model.add(layers.Reshape(target_shape=(7, 7, 30)))\n",
        "    \n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yolo= create_yolo()\n",
        "yolo.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vY9q_ML-f-_c",
        "outputId": "4e86eeeb-6ba4-4362-f1e5-91b6ed09de18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_17 (Conv2D)          (None, 224, 224, 64)      9472      \n",
            "                                                                 \n",
            " leaky_re_lu_16 (LeakyReLU)  (None, 224, 224, 64)      0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 112, 112, 64)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 112, 112, 192)     110784    \n",
            "                                                                 \n",
            " leaky_re_lu_17 (LeakyReLU)  (None, 112, 112, 192)     0         \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 56, 56, 192)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 56, 56, 128)       24704     \n",
            "                                                                 \n",
            " leaky_re_lu_18 (LeakyReLU)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " leaky_re_lu_19 (LeakyReLU)  (None, 56, 56, 256)       0         \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 56, 56, 256)       65792     \n",
            "                                                                 \n",
            " leaky_re_lu_20 (LeakyReLU)  (None, 56, 56, 256)       0         \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 56, 56, 512)       1180160   \n",
            "                                                                 \n",
            " leaky_re_lu_21 (LeakyReLU)  (None, 56, 56, 512)       0         \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 28, 28, 512)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 28, 28, 256)       131328    \n",
            "                                                                 \n",
            " leaky_re_lu_22 (LeakyReLU)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " leaky_re_lu_23 (LeakyReLU)  (None, 28, 28, 512)       0         \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 28, 28, 256)       131328    \n",
            "                                                                 \n",
            " leaky_re_lu_24 (LeakyReLU)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " leaky_re_lu_25 (LeakyReLU)  (None, 28, 28, 512)       0         \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 28, 28, 256)       131328    \n",
            "                                                                 \n",
            " leaky_re_lu_26 (LeakyReLU)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " leaky_re_lu_27 (LeakyReLU)  (None, 28, 28, 512)       0         \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 28, 28, 256)       131328    \n",
            "                                                                 \n",
            " leaky_re_lu_28 (LeakyReLU)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " conv2d_30 (Conv2D)          (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " leaky_re_lu_29 (LeakyReLU)  (None, 28, 28, 512)       0         \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 28, 28, 512)       262656    \n",
            "                                                                 \n",
            " leaky_re_lu_30 (LeakyReLU)  (None, 28, 28, 512)       0         \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (None, 28, 28, 1024)      4719616   \n",
            "                                                                 \n",
            " leaky_re_lu_31 (LeakyReLU)  (None, 28, 28, 1024)      0         \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 14, 14, 1024)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (None, 14, 14, 512)       524800    \n",
            "                                                                 \n",
            " leaky_re_lu_32 (LeakyReLU)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (None, 14, 14, 1024)      4719616   \n",
            "                                                                 \n",
            " leaky_re_lu_33 (LeakyReLU)  (None, 14, 14, 1024)      0         \n",
            "                                                                 \n",
            " conv2d_35 (Conv2D)          (None, 14, 14, 512)       524800    \n",
            "                                                                 \n",
            " leaky_re_lu_34 (LeakyReLU)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " conv2d_36 (Conv2D)          (None, 14, 14, 1024)      4719616   \n",
            "                                                                 \n",
            " leaky_re_lu_35 (LeakyReLU)  (None, 14, 14, 1024)      0         \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (None, 14, 14, 1024)      9438208   \n",
            "                                                                 \n",
            " leaky_re_lu_36 (LeakyReLU)  (None, 14, 14, 1024)      0         \n",
            "                                                                 \n",
            " conv2d_38 (Conv2D)          (None, 7, 7, 1024)        9438208   \n",
            "                                                                 \n",
            " leaky_re_lu_37 (LeakyReLU)  (None, 7, 7, 1024)        0         \n",
            "                                                                 \n",
            " conv2d_39 (Conv2D)          (None, 7, 7, 1024)        9438208   \n",
            "                                                                 \n",
            " leaky_re_lu_38 (LeakyReLU)  (None, 7, 7, 1024)        0         \n",
            "                                                                 \n",
            " conv2d_40 (Conv2D)          (None, 7, 7, 1024)        9438208   \n",
            "                                                                 \n",
            " leaky_re_lu_39 (LeakyReLU)  (None, 7, 7, 1024)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 50176)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              205524992 \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1470)              6022590   \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 7, 7, 30)          0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 271,703,550\n",
            "Trainable params: 271,703,550\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pascal VOC Dataset load\n",
        "dataset.py\n",
        "xml 파일 다루기"
      ],
      "metadata": {
        "id": "noFelUqVBUh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import numpy\n",
        "import xml.etree.ElementTree as ET\n",
        "import tqdm\n",
        "\n",
        "classes_num = {'aeroplane': 0, 'bicycle': 1, 'bird': 2, 'boat': 3, 'bottle': 4, \n",
        "               'bus': 5, 'car': 6, 'cat': 7, 'chair': 8, 'cow': 9, \n",
        "               'diningtable': 10, 'dog': 11, 'horse': 12, 'motorbike': 13, 'person': 14, \n",
        "               'pottedplant': 15, 'sheep': 16, 'sofa': 17, 'train': 18, 'tvmonitor': 19}\n",
        "\n",
        "classes = list(classes_num.keys())\n",
        "\n",
        "\n",
        "def voc_load_data(img_dir_path, annotation_path, batch=10):\n",
        "    images, labels = [], []\n",
        "    img_file_list = glob.glob((img_dir_path + \"/*.jpg\"))\n",
        "\n",
        "    for i in range(len(img_file_list)):\n",
        "        for img_path in tqdm.tqdm(img_file_list[batch * i: batch * (i + 1)]):\n",
        "\n",
        "            # Read image\n",
        "            image = cv2.imread(img_path)\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            image_h, image_w = image.shape[0:2]\n",
        "\n",
        "            # Resize (x, y)크기 이미지 -> (488, 488)로 변경\n",
        "            image = cv2.resize(image, (488,488))\n",
        "            # normalization 이미지 데이터를 0~1 사이의 값으로 변경 - 정규화 진행\n",
        "            image = image / 255.0\n",
        "\n",
        "            images.append(image)\n",
        "\n",
        "            # Read xml file\n",
        "            xml_name = os.path.split(img_path)[-1]\n",
        "            xml_name = xml_name.split(\".\")[-2]\n",
        "            xml_path = annotation_path + f\"/{xml_name}.xml\"\n",
        "\n",
        "            # parse xml\n",
        "            tree = ET.parse(xml_path)\n",
        "            root = tree.getroot()\n",
        "\n",
        "            # Empty matrix, (7, 7, 25)크기의 0으로 채워진 label_matrix \n",
        "            label_matrix = numpy.zeros((7, 7, 25)) # 정답에 해당하는 레이블(은 바운딩 박스가 하나다)\n",
        "\n",
        "            for obj in root.iter('object'):\n",
        "                difficult = obj.find('difficult').text\n",
        "                class_name = obj.find('name').text\n",
        "                if class_name not in classes or difficult == \"1\":\n",
        "                    continue\n",
        "\n",
        "                # Set class id\n",
        "                cls_id = classes.index(class_name)\n",
        "                xmlbox = obj.find('bndbox')\n",
        "                tlx, tly = int(xmlbox.find('xmin').text), int(xmlbox.find('ymin').text)\n",
        "                brx, bry = int(xmlbox.find('xmax').text), int(xmlbox.find('ymax').text)\n",
        "\n",
        "                # x좌표, y좌표를 0~1 사이의 값으로 일반화(정규화)\n",
        "                x = (brx + tlx) / 2 / image_w #가운데 좌표(스케일)\n",
        "                y = (bry + tly) / 2 / image_h\n",
        "                \n",
        "                # w, h를 0~1 사이의 값으로 일반화(정규화)\n",
        "                w = (brx - tlx) / image_w # 가로 길이\n",
        "                h = (bry - tly) / image_h # 세로 길이\n",
        "\n",
        "                # (7x7)그리드 셀의 좌표와 셀 안에서의 좌표\n",
        "                loc = [7 * x, 7 * y]\n",
        "                loc_i = int(loc[1]) # 그리드 좌표 y 7x7 그리드기에 실수에서 정수로 딱 바꿔줘야 함\n",
        "                loc_j = int(loc[0]) # 그리드 좌표 x\n",
        "                y = loc[1] - loc_i # 그리드 셀 안에서의 y좌표\n",
        "                x = loc[0] - loc_j # 그리드 셀 안에서의 x좌표\n",
        "\n",
        "                if label_matrix[loc_i, loc_j, 24] == 0:\n",
        "                    # [<----------20---------->|x|y|w|h|pc]\n",
        "                    label_matrix[loc_i, loc_j, cls_id] = 1 #정답데이터니까 객체 class도 바르게 맞췄겠지\n",
        "                    # 20 class 중 해당하는 하나에 1 넣어주는것\n",
        "                    label_matrix[loc_i, loc_j, 20:24] = [x, y, w, h]\n",
        "                    label_matrix[loc_i, loc_j, 24] = 1  # response - 정답데이터이기에 PC값이 무조건 1이지\n",
        "\n",
        "            labels.append(label_matrix)\n",
        "\n",
        "        return numpy.array(images), numpy.array(labels)"
      ],
      "metadata": {
        "id": "0jh1C_aOgTnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras import datasets, layers, models, activations, losses, optimizers, metrics, utils\n",
        "import model\n",
        "import loss\n",
        "import dataset\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    train_images, train_labels = dataset.voc_load_data(\"./VOC2007/images\", \"./VOC2007/labels\")    \n",
        "\n",
        "    yolo = model.create_yolo()\n",
        "\n",
        "    with tensorflow.device(\"/cpu:0\"):\n",
        "        yolo.compile(optimizer=optimizers.Adam(), loss=loss.yolo_loss)\n",
        "        yolo.fit(train_images, train_labels, epochs=1, verbose=2)\n",
        "        result = yolo.evaluate(train_images, train_labels)\n",
        "        print(result)\n",
        "\n",
        "    # 수정하지 마세요. 채점에 사용되는 코드입니다.\n",
        "    print(train_images[0, :, :, :].sum())\n",
        "    print(train_labels[0, :, :, :].sum())\n"
      ],
      "metadata": {
        "id": "NwrSlvVEBi1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generator 사용해서 Batch 단위로 학습하기\n",
        "data_generator.py"
      ],
      "metadata": {
        "id": "jQL5G-FaKBvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import math\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import numpy\n",
        "import xml.etree.ElementTree as ET\n",
        "import glob\n",
        "import os\n",
        "\n",
        "\n",
        "classes_num = {'aeroplane': 0, 'bicycle': 1, 'bird': 2, 'boat': 3, 'bottle': 4, 'bus': 5,\n",
        "               'car': 6, 'cat': 7, 'chair': 8, 'cow': 9, 'diningtable': 10, 'dog': 11,\n",
        "               'horse': 12, 'motorbike': 13, 'person': 14, 'pottedplant': 15, 'sheep': 16,\n",
        "               'sofa': 17, 'train': 18, 'tvmonitor': 19}\n",
        "\n",
        "classes = list(classes_num.keys())\n",
        "\n",
        "\n",
        "class SequenceData(keras.utils.Sequence): # 데이터를 연속적으로 batch로 잘라서 처리하도록 한다\n",
        "\n",
        "    def __init__(self, model, img_dir_path, annotation_path, target_size, batch_size, shuffle=True):\n",
        "        self.model = model\n",
        "        self.datasets = glob.glob((img_dir_path + \"/*.jpg\")) #여기 조정해서 train, test, val dataset 다르게 설정 가능\n",
        "        self.image_path = img_dir_path\n",
        "        self.label_path = annotation_path\n",
        "        self.image_size = target_size[0:2]\n",
        "        self.batch_size = batch_size\n",
        "        self.indexes = np.arange(len(self.datasets)) # __getitem__에 쓰임(아마도)\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "    def __len__(self): #배치 당 데이터셋의 길이\n",
        "        num_imgs = len(self.datasets)\n",
        "        return math.ceil(num_imgs / float(self.batch_size)) # 1000개를 100개씩 10번 묶으면 100 반환\n",
        "\n",
        "    def __getitem__(self, idx): # iterable한 객치(튜플, 리스트 등등)에서 아이템 가져다주는 함수\n",
        "        batch_index = self.indexes[idx * self.batch_size: ((idx + 1) * self.batch_size)] # 101~200까지 슬라이싱\n",
        "        batch = [self.datasets[k] for k in batch_index] # 101~200번째의 파일경로가 들어있음\n",
        "        # idx는 idx 번째 배치 데이터 셋을 의미합니다.\n",
        "        # idx = 2라면, 전체 데이터 셋 / 배치 사이즈 하였을 때 2번째 묶음을 의미\n",
        "        # ex) 1000개 100개씩 묶었음 101~200까지의 데이터들\n",
        "        \n",
        "        # 아래 함수의 인자로 들어가는 batch는 전체 데이터셋 이미지 경로들 중 일부가 담rla\n",
        "        # 알맞은 갯수의 이미지와 대응하는 라벨값을 전달\n",
        "        X, y = self.data_generation(batch)\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes) #인덱스를 섞어서 getitem에서 바꿔서 가져오게 한다(shuffle의 내부적인 부분)\n",
        "\n",
        "    def read(self, image_path): #이건 한 데이터에 대한 처리(dataset.py는 전체를 for문으로 돌았음)\n",
        "        xml_path = os.path.join(os.path.abspath(self.label_path),\n",
        "                                os.path.split(image_path)[-1].split('.')[0]) + \".xml\"\n",
        "\n",
        "        image = cv.imread(image_path)\n",
        "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "        image_h, image_w = image.shape[0:2]\n",
        "        image = cv.resize(image, self.image_size)\n",
        "        image = image / 255.\n",
        "\n",
        "        tree = ET.parse(xml_path)\n",
        "        root = tree.getroot()\n",
        "        label_matrix = numpy.zeros([7, 7, 25])\n",
        "\n",
        "        label_matrix = np.zeros([7, 7, 25])\n",
        "        for obj in root.iter('object'):\n",
        "            difficult = obj.find('difficult').text\n",
        "            class_name = obj.find('name').text\n",
        "            if class_name not in classes or difficult == \"1\":\n",
        "                continue\n",
        "\n",
        "            cls_id = classes.index(class_name)\n",
        "            xmlbox = obj.find('bndbox')\n",
        "            tlx, tly = int(xmlbox.find('xmin').text), int(xmlbox.find('ymin').text)\n",
        "            brx, bry = int(xmlbox.find('xmax').text), int(xmlbox.find('ymax').text)\n",
        "            x = (tlx + brx) / 2 / image_w\n",
        "            y = (tly + bry) / 2 / image_h\n",
        "            w = (brx - tlx) / image_w\n",
        "            h = (bry - tly) / image_h\n",
        "\n",
        "            loc = [7 * x, 7 * y]\n",
        "            loc_i = int(loc[1])\n",
        "            loc_j = int(loc[0])\n",
        "            y = loc[1] - loc_i\n",
        "            x = loc[0] - loc_j\n",
        "\n",
        "            if label_matrix[loc_i, loc_j, 24] == 0:\n",
        "                label_matrix[loc_i, loc_j, cls_id] = 1\n",
        "                label_matrix[loc_i, loc_j, 20:24] = [x, y, w, h]\n",
        "                label_matrix[loc_i, loc_j, 24] = 1  # response\n",
        "\n",
        "        return image, label_matrix\n",
        "\n",
        "    def data_generation(self, batch_datasets): #파일경로가 들어있음\n",
        "        images = []\n",
        "        labels = []\n",
        "\n",
        "        for file_path in batch_datasets: # 각 경로의 파일 읽어서 images, labels에 넣어줌(배치 단위로)\n",
        "            image, label = self.read(file_path)\n",
        "            images.append(image)\n",
        "            labels.append(label)\n",
        "        \"\"\"\n",
        "        들어온 batch_datasets 만큼의 이미지와 라벨링 데이터를 전달할 수 있도록 하세요.\n",
        "        예를 들어 전체 데이터 중 batch_size 가 10이라면 batch_datsets에는 전체 데이터 / 10 만큼의 이미지 파일 경로들이 담겨있습니다.\n",
        "        \"\"\"\n",
        "        return np.array(images), np.array(labels)"
      ],
      "metadata": {
        "id": "TJYUA6ihKJXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras import datasets, layers, models, activations, losses, optimizers, metrics, utils\n",
        "import model\n",
        "import loss\n",
        "import data_generator\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # train_images, train_labels = dataset.voc_load_data(\"./VOCdevkit/VOC2007/JPEGImages\", \"./VOCdevkit/VOC2007/Annotations\", batch=1000)\n",
        "    \n",
        "    yolo = model.create_yolo()\n",
        "    \n",
        "    yolo.compile(optimizer=optimizers.Adam(), loss=loss.yolo_loss)\n",
        "    train_generator = data_generator.SequenceData(\"train\",\n",
        "                                                  \"./VOC2007/images\",\n",
        "                                                  \"./VOC2007/labels\",\n",
        "                                                  (448, 448, 3),\n",
        "                                                  batch_size=10,\n",
        "                                                  shuffle=True)\n",
        "\n",
        "    yolo.fit_generator(generator=train_generator,\n",
        "                       steps_per_epoch=len(train_generator),\n",
        "                       epochs=1,\n",
        "                       use_multiprocessing=True,\n",
        "                       workers=4)\n",
        "                       \n",
        "    x, y = train_generator[0]\n",
        "    print('첫 번째 데이터 셋:', x.shape, y.shape)"
      ],
      "metadata": {
        "id": "9LASUBinKeZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callback으로 특정 주기마다 모델 저장\n",
        "\n",
        "* yolo.fit_generator에 callbacks 인자가 있다\n",
        "* train의 시작과 끝, 매 epoch의 시작과 끝에 모델 저장 설정가능\n",
        "* 특정 loss 도달했을 때 학습 멈추고 모델 저장도 가능  \n",
        "\n",
        "main.py에 넣음"
      ],
      "metadata": {
        "id": "Dyau_ULyd6mF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras import datasets, layers, models, activations, losses, optimizers, metrics, utils, callbacks\n",
        "import model\n",
        "import loss\n",
        "import data_generator\n",
        "\n",
        "# 매 epoch 마다 모델을 저장하는 callback\n",
        "class MyCallback(callbacks.Callback):\n",
        "    #on_train_begin(): 학습이 시작될 때 호출\n",
        "    #on_train_end(): 학습이 끝날 때 호출\n",
        "    #on_epoch_begin(): epoch가 시작될 때 호출\n",
        "    #on_epoch_end(): epoch가 끝날 때 호출\n",
        "    #위의 네 개의 함수를 오버라이딩 가능\n",
        "    def on_train_begin(self, logs=None):\n",
        "        print(\"학습이 시작되었습니다.\")\n",
        "        if logs is not None:\n",
        "            print(logs)\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        print(\"학습이 완료되었습니다.\")\n",
        "        if logs is not None:\n",
        "            print(logs)\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None): #f-string formatting\n",
        "        print(f\"{epoch}회차 학습이 시작되었습니다.\")\n",
        "        if logs is not None:\n",
        "            print(logs)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print(f\"{epoch}회차 학습이 완료되었습니다.\")\n",
        "        self.model.save_weights(f\"my-yolov1-{epoch}.hdf5\")\n",
        "        print(f\"my-yolov1-{epoch}.hdf5 저장 완료\")\n",
        "        if logs is not None:\n",
        "            print(logs)\n",
        "        \n",
        "    pass\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    yolo = model.create_yolo()\n",
        "    \n",
        "    yolo.compile(optimizer=optimizers.Adam(), loss=loss.yolo_loss)\n",
        "    train_generator = data_generator.SequenceData(\"train\",\n",
        "                                                  \"./VOC2007/images\",\n",
        "                                                  \"./VOC2007/labels\",\n",
        "                                                  (448, 448, 3),\n",
        "                                                  batch_size=10,\n",
        "                                                  shuffle=True)\n",
        "\n",
        "    yolo.fit_generator(\n",
        "        generator=train_generator,\n",
        "        steps_per_epoch=len(train_generator),\n",
        "        epochs=3,\n",
        "        use_multiprocessing=True,\n",
        "        workers=4,\n",
        "        callbacks=[MyCallback()]\n",
        "    )"
      ],
      "metadata": {
        "id": "ueBLDbVEKope"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 출력 텐서 decoding\n",
        "\n",
        "* yolo의 출력텐서는 7x7x30으로 이루어짐\n",
        "\n",
        "![](https://elice-api-cdn.azureedge.net/api-attachment/attachment/72bcbfe646e145baa4fddc2236a8b2ac/image.png)  \n",
        "\n",
        "* 이처럼 7x7 그리드를 순회하며 output tensor로 바운딩박스를 그린다\n",
        "   총 7x7x2, 98개의 바운딩 박스가 그려졌을 것(NMS를 안써서 개수 안줄어듦)\n",
        "\n",
        "decoder.py"
      ],
      "metadata": {
        "id": "TxWFjt08pW3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "\n",
        "\n",
        "# 출력 텐서를 해석하여 x, y, w, h로 표현되는 바운딩 박스를 리턴하는 함수\n",
        "\n",
        "def decode(y, image_w, image_h):# y는 (1,7,7,30) shape - 1은 배치 사이즈\n",
        "    boxes = []\n",
        "    \n",
        "    \n",
        "    # 7 x 7의 그리드 셀을 순회\n",
        "    for i in range(7):\n",
        "        for j in range(7):\n",
        "            grid_vector = y[0]\n",
        "                \n",
        "            # 두 개의 Anchorbox\n",
        "            # AnchorBox는 = [x, y, w, h] 로 구성\n",
        "            # 이때 x, y는 셀 안에서의 중심 좌표!\n",
        "            anchor_boxA = grid_vector[i, j, 20:25]\n",
        "            anchor_boxB = grid_vector[i, j, 25:]\n",
        "            box1 = anchor_boxA.copy()\n",
        "            box2 = anchor_boxB.copy()\n",
        "                \n",
        "            # 첫번째 Anchor Box의 셀 안에서의 좌표를 이용하여\n",
        "            # 원래 이미지에서 중심 좌표로 변환 합니다.\n",
        "            # 박스의 가로, 세로 역시 마찬가지로 좌표를 원본 이미지에 맞게 조정\n",
        "            box1[0] = (j + box1[0]) / 7 * image_w #이미지 상의 x좌표\n",
        "            box1[1] = (j + box1[1]) / 7 * image_h\n",
        "            box1[2] = box1[2] * image_w\n",
        "            box1[3] = box1[3] * image_h\n",
        "\n",
        "            # 두번째 Anchor Box의 셀 안에서의 좌표를 이용하여\n",
        "            # 원래 이미지에서 중심 좌표로 변환\n",
        "            # 박스의 가로, 세로 역시 마찬가지로 좌표를 원본 이미지에 맞게 조정\n",
        "            box2[0] = (j + box2[0]) / 7 * image_w\n",
        "            box2[1] = (j + box2[1]) / 7 * image_h\n",
        "            box2[2] = box2[2] * image_w\n",
        "            box2[3] = box2[3] * image_h\n",
        "\n",
        "            # 첫번째 박스의 중심좌표를 tlx, tly로 변환\n",
        "            box1[0] -= (box1[2] / 2)\n",
        "            box1[1] -= (box1[3] / 2)\n",
        "\n",
        "            # 두번째 박스의 중심좌표를 tlx, tly으로 변환\n",
        "            box2[0] -= (box2[2] / 2)\n",
        "            box2[1] -= (box2[3] / 2)\n",
        "\n",
        "            boxes.append(box1)\n",
        "            boxes.append(box2)\n",
        "\n",
        "    return boxes"
      ],
      "metadata": {
        "id": "N-mWdSdupZYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras import datasets, layers, models, activations, losses, optimizers, metrics, utils\n",
        "import model\n",
        "import loss\n",
        "import decoder\n",
        "import cv2\n",
        "import numpy\n",
        "\n",
        "\n",
        "from elice_utils import EliceUtils\n",
        "\n",
        "\n",
        "elice_utils = EliceUtils()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    yolo = model.create_yolo()\n",
        "    yolo.summary()\n",
        "\n",
        "    yolo.load_weights(\"weights_checkpoint_1.hdf5\")\n",
        "\n",
        "    input_shape = (1, 448, 448, 3)\n",
        "\n",
        "    image = cv2.imread(\"./000001.jpg\")\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, input_shape[1:3])\n",
        "    draw = image.copy()\n",
        "    draw = cv2.cvtColor(draw, cv2.COLOR_RGB2BGR)\n",
        "    image_h, image_w = image.shape[0:2]\n",
        "\n",
        "    # 모델 입력에 맞게 reshaping 후 정규화\n",
        "    image = numpy.reshape(image, input_shape)\n",
        "    image = image / 255.\n",
        "\n",
        "    y = yolo.predict(image, batch_size=1)\n",
        "    boxes = decoder.decode(y, image_h, image_w)\n",
        "\n",
        "\n",
        "    for box in boxes:\n",
        "        cv2.rectangle(draw, (int(box[0]), int(box[1])),\n",
        "                      (int(box[0] + box[2]), int(box[1] + box[3])), (255, 0, 255))\n",
        "\n",
        "\n",
        "    cv2.imwrite(\"result.jpg\", draw)    \n",
        "    elice_utils.send_image('result.jpg')"
      ],
      "metadata": {
        "id": "34fkMJLjrQeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 출력 텐서 디코딩에 NMS 적용\n",
        "\n",
        "![](https://elice-api-cdn.azureedge.net/api-attachment/attachment/cd88ad0b4ac1438cb89df943f97ab753/image.png)\n",
        "* 이렇게 박스들이 confidence threshold보다 낮을 경우 삭제되고 NMS 적용으로 기준 박스와의 IOU가 IoU Threshold보다 높으면 삭제되면서 걸려진다  \n",
        "decoder.py"
      ],
      "metadata": {
        "id": "460vr5M3wB_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "\n",
        "\n",
        "classes_num = {'aeroplane': 0, 'bicycle': 1, 'bird': 2, 'boat': 3, 'bottle': 4, 'bus': 5,\n",
        "               'car': 6, 'cat': 7, 'chair': 8, 'cow': 9, 'diningtable': 10, 'dog': 11,\n",
        "               'horse': 12, 'motorbike': 13, 'person': 14, 'pottedplant': 15, 'sheep': 16,\n",
        "               'sofa': 17, 'train': 18, 'tvmonitor': 19}\n",
        "\n",
        "classes = list(classes_num.keys())\n",
        "\n",
        "\n",
        "\n",
        "def intersection_over_union(box1, box2):\n",
        "\n",
        "    # 교집합 부분의 top left 좌표와 bottom right 좌표 계산\n",
        "    x1 = numpy.maximum(box1[0], box2[0])\n",
        "    y1 = numpy.maximum(box1[1], box2[1])\n",
        "    x2 = numpy.minimum(box1[0] + box1[2], box2[0] + box2[2])\n",
        "    y2 = numpy.minimum(box1[1] + box1[3], box2[1] + box2[3])\n",
        "\n",
        "    # 교집합의 넒이\n",
        "    intersection = numpy.maximum(x2 - x1, 0) * numpy.maximum(y2 - y1, 0)\n",
        "\n",
        "    # 박스1의 넓이와 박스2의 넓이\n",
        "    box1_area = box1[2] * box1[3]\n",
        "    box2_area = box2[2] * box2[3]\n",
        "\n",
        "    # 두 박스의 넒이를 더한뒤 교집합 영역 넓이를 뺴면 합영역\n",
        "    union = box1_area + box2_area - intersection\n",
        "\n",
        "    # iou 계산\n",
        "    iou = intersection / union\n",
        "    return iou\n",
        "\n",
        "\n",
        "def decode(y, image_shape, class_confidence_threshold=0.2, iou_threshold=0.2):\n",
        "    boxes, names = [], [] #박스에 클래스 이름 써있도록\n",
        "    grid_vector = y[0]\n",
        "    \n",
        "    # NMS 진행 : IOU가 높아 겹치는 박스를 제거\n",
        "    # 아래 NMS 배열은 98개의 클래스 별 신뢰도를 담을 행렬\n",
        "    # 0 ~ 20 행까지는 클래스 별 신뢰도를, 20 ~ 25행 까지는 AnchorBox의 좌표와 신뢰도 값을 저장\n",
        " \n",
        "    nms = numpy.zeros((25, 98))\n",
        "    for i in range(7):\n",
        "        for j in range(7):\n",
        "            box_num = i * 7 + j\n",
        "            # AnchorBox A\n",
        "            nms[:20, box_num] = grid_vector[i, j, 0:20]\n",
        "            # 박스의 confidence를 클래스 confidence에 곱하여 \n",
        "            # 박스의 위치와 클래스 모두 고려될 수 있도록\n",
        "            nms[:20, box_num] *= grid_vector[i, j, 24]\n",
        "            nms[20:, box_num] = grid_vector[i, j, 20:25]\n",
        "                                \n",
        "            # 박스 좌표 변환 : 그리드 셀에서 좌표를 -> x, y, w, h로 image_shape에 맞게\n",
        "            nms[20, box_num] = (j + grid_vector[i, j, 20]) / 7 * image_shape[1]\n",
        "            nms[21, box_num] = (i + grid_vector[i, j, 21]) / 7 * image_shape[0]\n",
        "            nms[22, box_num] = grid_vector[i, j, 22] * image_shape[1]\n",
        "            nms[23, box_num] = grid_vector[i, j, 23] * image_shape[0]\n",
        "                  \n",
        "            # 박스의 중심좌표를 x1, y1으로 변환\n",
        "            nms[20, box_num] -= (nms[22, box_num] / 2)\n",
        "            nms[21, box_num] -= (nms[23, box_num] / 2)\n",
        "            \n",
        "\n",
        "            # AnchorBox B\n",
        "            nms[:20, box_num + 1] = grid_vector[i, j, 0:20]\n",
        "            # 박스의 confidence를 클래스 confidence에 곱하여 \n",
        "            # 박스의 위치와 클래스 모두 고려될 수 있도록\n",
        "            nms[:20, box_num + 1] *= grid_vector[i, j, -1]\n",
        "            nms[20:, box_num + 1] = grid_vector[i, j, 25:]\n",
        "            \n",
        "            # 박스 좌표 변환 : 그리드 셀에서 좌표를 -> x, y, w, h로 image_shape에 맞게\n",
        "            nms[20, box_num + 1] = (j + grid_vector[i, j, 25]) / 7 * image_shape[1]\n",
        "            nms[21, box_num + 1] = (i + grid_vector[i, j, 26]) / 7 * image_shape[0]\n",
        "            nms[22, box_num + 1] = grid_vector[i, j, 27] * image_shape[1]\n",
        "            nms[23, box_num + 1] = grid_vector[i, j, 28] * image_shape[0]\n",
        "                    \n",
        "            # 박스의 중심좌표를 x1, y1으로 변환\n",
        "            nms[20, box_num + 1] -= (nms[22, box_num + 1] / 2)\n",
        "            nms[21, box_num + 1] -= (nms[23, box_num + 1] / 2)\n",
        "\n",
        "    # 아래 주석을 해제하면, nms 배열에 클래스 별 신뢰도 값이 복사되었는지 알 수 있음\n",
        "    # for c in range(20):\n",
        "    #     for k in range(0, 98):\n",
        "    #         print(f\"{classes[c]}에 대한 {k} 번째 박스 신뢰도는 {nms[c, k]}\")\n",
        "\n",
        "    # 모든 클래스 마다\n",
        "    for class_id in range(nms.shape[0] - 5):\n",
        "        # 모든 박스별로\n",
        "        for box_order in range(nms.shape[1]):\n",
        "\n",
        "            # 클래스의 신뢰도가 낮으면 주어진 클래스 threshold 보다 낮으면\n",
        "            # 해당 클래스 신뢰도를 0으로\n",
        "            if nms[class_id, box_order] < class_confidence_threshold:            \n",
        "                nms[class_id, box_order] = 0\n",
        "                pass\n",
        "\n",
        "        # class confidence값에 따라 소팅하여(내림차순)\n",
        "        # 클래스 별로 해당 클래스에서 IOU가 높은 것을 제거하도록 \n",
        "        # 해당 박스의 클래스에 신뢰도 0으로\n",
        "        candidates = nms[class_id, :].argsort()[::-1]\n",
        "        for i in range(candidates.shape[0]): #기준박스에 대한 loop\n",
        "            for j in range(i + 1, candidates.shape[0]): #기준박스와의 비교\n",
        "                box1 = nms[20:24, candidates[i]]\n",
        "                box2 = nms[20:24, candidates[j]]\n",
        "                iou = intersection_over_union(box1, box2) #기존에 구현한 것과 iou 인자 조금 다름\n",
        "                \n",
        "                if iou > iou_threshold:\n",
        "                    nms[class_id, candidates[j]] = 0\n",
        "                    \n",
        "    # 아래 주석을 해제하면 IOU로 제거된 이후의 신뢰도 출력\n",
        "    # for c in range(20):\n",
        "    #     for k in range(0, 98):\n",
        "    #         print(f\"{classes[c]}에 대한 {k} 번째 박스 신뢰도는 {nms[c, k]}\")\n",
        "    \n",
        "    # 이제 남은 박스들 중 점수가 0이상인 박스들만\n",
        "    # 좌표를 x. y, w, h로 변환\n",
        "    for box_num in range(nms.shape[1]):\n",
        "        class_id = numpy.argmax(nms[:20, box_num])\n",
        "        confidence = nms[class_id, box_num]\n",
        "                \n",
        "        if confidence > 0:\n",
        "            box = nms[20:24, box_num].copy()\n",
        "            boxes.append(box)\n",
        "            names.append(classes[class_id])\n",
        "    \n",
        "    return boxes, names"
      ],
      "metadata": {
        "id": "eJsYSfz6wAEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 실신 감지 알고리즘(w/ yolov3tiny)\n",
        "* 침대가 있는 영역을 rectangle로 잡아 roi로 설정\n",
        "* 사람 객체의 바운딩박스 중심이 roi에 포함되면 바운딩박스 색 변함\n",
        "* 그러고 5초 이상(150프레임) 지속되면 falldown으로 감지\n",
        "* 다시 roi 밖으로 나가면 실신 아니었거나 풀린 것"
      ],
      "metadata": {
        "id": "0-0cMk4pnCVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import tensorflow as tf\n",
        "from yolov3.models import YoloV3Tiny\n",
        "\n",
        "from yolov3.dataset import transform_images\n",
        "from yolov3.utils import draw_outputs\n",
        "\n",
        "\n",
        "from answer import answer\n",
        "\n",
        "\n",
        "def convert_outputs(outputs):\n",
        "    ret_boxes, ret_scores, ret_classes = [], [], []\n",
        "\n",
        "    boxes, scores, classes, nums = outputs\n",
        "    boxes, scores, classes, nums = list(boxes[0]), list(scores[0]), list(classes[0]), nums[0]\n",
        "\n",
        "    for i in range(nums):\n",
        "        box, score, class_idx = boxes[i], scores[i], classes[i]\n",
        "        ret_boxes.append(box)\n",
        "        ret_scores.append(score)\n",
        "        ret_classes.append(class_names[class_idx])\n",
        "\n",
        "    return ret_boxes, ret_scores, ret_classes\n",
        "\n",
        "# 박스의 중간 좌표가 roi안에 들어있으면 1, 아니면 0\n",
        "def isInRoi(cx, cy, roi): \n",
        "    return (roi[0]<cx and cx<roi[2] and roi[1]<cy and cy < roi[3])\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    class_names = [c.strip() for c in open('./coco.names').readlines()]\n",
        "    yolo = YoloV3Tiny(classes=len(class_names))\n",
        "    yolo.load_weights('./checkpoints/yolov3-tiny.tf')\n",
        "\n",
        "    vid = cv2.VideoCapture(\"cam5.avi\")\n",
        "\n",
        "    falldown_start, falldown_end = 0, 0\n",
        "    frame_number = 0\n",
        "\n",
        "    roi = [250,220,400,320]\n",
        "    hit, falldown_start, falldown_end = 0, 0, 0\n",
        "    status = \"normal\"\n",
        "\n",
        "    while vid.isOpened():\n",
        "        _, img = vid.read()\n",
        "\n",
        "        if img is None:\n",
        "            continue\n",
        "\n",
        "        img_in = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img_in = tf.expand_dims(img_in, 0)\n",
        "        img_in = transform_images(img_in, 416)\n",
        "        boxes, scores, classes = convert_outputs(yolo.predict(img_in))\n",
        "        color = (255, 0, 0)\n",
        "        \n",
        "        \n",
        "        #boxes에는 박스의 (x1,y2), (x2,y2) 좌표가 실수로 있음\n",
        "        #scores에는 박스의 confidence 값이 있고, classes에는 str타입에 박스의 클래스 이름\n",
        "     \n",
        "      \n",
        "\n",
        "        for box in boxes:\n",
        "            # box의 중심 좌표\n",
        "            cx = (box[0] * img.shape[1] + box[2] * img.shape[1]) // 2\n",
        "            cy = (box[1] * img.shape[0] + box[3] * img.shape[0]) // 2\n",
        "\n",
        "            cv2.circle(img, (int(cx), int(cy)), 10, (255, 255, 128), 1)\n",
        "\n",
        "            in_roi = isInRoi(cx, cy, roi)\n",
        "            if status == \"mornal\" and in_roi:\n",
        "                color = (0, 0, 128)\n",
        "                hit += 1\n",
        "                status = \"test\"\n",
        "            elif status == \"test\" and in_roi:\n",
        "                hit += 1\n",
        "                if hit > 150: #30fps영상에서의 5초 이상!\n",
        "                    status = \"falldown\"\n",
        "                    color = (0, 0, 255)\n",
        "                    falldown_start = frame_number\n",
        "                    print(f\"실신시작 - {falldown_start}\")\n",
        "            elif status == \"falldown\":\n",
        "                if in_roi:\n",
        "                    color = (0, 0, 255)\n",
        "                else:\n",
        "                    color = (255, 0, 0)\n",
        "                    status = \"normal\"\n",
        "                    hit = 0\n",
        "                    falldown_end = frame_number\n",
        "                    print(f\"실신시작 - {falldown_end}\")\n",
        "\n",
        "        \n",
        "        cv2.rectangle(img, (roi[0], roi[1]), (roi[2], roi[3]), color, 2)\n",
        "        \n",
        "        cv2.putText(img, f\"{frame_number}\",(20, 20),\n",
        "                    cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, color, 2)\n",
        "       \n",
        "                    \n",
        "        for box, score, class_name in zip(boxes, scores, classes):\n",
        "            box[0] *= img.shape[1]\n",
        "            box[1] *= img.shape[0]\n",
        "            box[2] *= img.shape[1]\n",
        "            box[3] *= img.shape[0]\n",
        "            cv2.rectangle(img, (int(box[0]), int(box[1])),\n",
        "                               (int(box[2]), int(box[3])), color, 2)\n",
        "            cv2.putText(img, f\"{class_name} {score:.3f}\",\n",
        "                        (int(box[0]), int(box[1])),\n",
        "                        cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, color, 2)\n",
        "\n",
        "        frame_number += 1\n",
        "        cv2.imshow('output', img)\n",
        "        if cv2.waitKey(1) == ord('q'):\n",
        "            break\n",
        "\n",
        "    cv2.destroyAllWindows()\n",
        "    \n",
        "    # 정답을 출력합니다.\n",
        "    answer(falldown_start, falldown_end)\n",
        "    "
      ],
      "metadata": {
        "id": "RKt52giUnA5d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}